"""
AI-FTB (AI-Powered Financial Trading Bot) Machine Learning Model Module

Bu modÃ¼l, makine Ã¶ÄŸrenimi modelini eÄŸitir, kaydeder, yÃ¼kler ve alÄ±m-satÄ±m 
sinyalleri Ã¼retir. Scikit-learn kÃ¼tÃ¼phanesini kullanarak sÄ±nÄ±flandÄ±rma 
modelleri oluÅŸturur.
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score
import joblib
import os
from datetime import datetime
import config
import logger


def prepare_data_for_ml(dataframe, target_column_name='Target', test_size=0.2):
    """
    DataFrame'i makine Ã¶ÄŸrenimi iÃ§in X (Ã¶zellikler) ve y (hedef) olarak ayÄ±rÄ±r.
    Hedef olarak bir sonraki gÃ¼nÃ¼n kapanÄ±ÅŸ fiyatÄ±nÄ±n artÄ±p artmayacaÄŸÄ±nÄ± 
    (1 artÄ±ÅŸ, 0 dÃ¼ÅŸÃ¼ÅŸ/sabit) binary sÄ±nÄ±flandÄ±rma problemi olarak tanÄ±mlar.
    
    Args:
        dataframe (pandas.DataFrame): Ã–zellikler ve hedef iÃ§eren veri
        target_column_name (str): Hedef deÄŸiÅŸken sÃ¼tun adÄ±
        test_size (float): Test verisi oranÄ± (0.0-1.0 arasÄ±)
    
    Returns:
        tuple: (X_train, X_test, y_train, y_test, feature_names)
        None: Hata durumunda
        
    Raises:
        Exception: Veri hazÄ±rlama hatalarÄ±nda
    """
    try:
        logger.log_info("Veri ML iÃ§in hazÄ±rlanÄ±yor...")
        
        # Hedef sÃ¼tununu kontrol et
        if target_column_name not in dataframe.columns:
            logger.log_error(f"Hedef sÃ¼tun bulunamadÄ±: {target_column_name}")
            return None
            
        # ML Ã¶zelliklerini config'ten al ve mevcut olanlarÄ± filtrele
        ml_features = config.ML_FEATURES.copy()
        
        # Ã–lÃ§eklendirilmiÅŸ Ã¶zellikleri de dahil et
        scaled_features = [f"{feature}_scaled" for feature in ml_features]
        all_possible_features = ml_features + scaled_features
        
        # Mevcut Ã¶zellikleri bul
        available_features = [f for f in all_possible_features if f in dataframe.columns]
        
        if not available_features:
            logger.log_error("KullanÄ±labilir ML Ã¶zelliÄŸi bulunamadÄ±")
            return None
            
        logger.log_info(f"KullanÄ±lacak Ã¶zellikler ({len(available_features)}): {available_features}")
        
        # Veriyi temizle - NaN iÃ§eren satÄ±rlarÄ± kaldÄ±r
        clean_data = dataframe[available_features + [target_column_name]].dropna()
        
        if len(clean_data) < 100:  # Minimum veri kontrolÃ¼
            logger.log_error(f"Yetersiz temiz veri: {len(clean_data)} satÄ±r")
            return None
            
        # X (Ã¶zellikler) ve y (hedef) olarak ayÄ±r
        X = clean_data[available_features]
        y = clean_data[target_column_name]
        
        # Hedef deÄŸiÅŸkenin daÄŸÄ±lÄ±mÄ±nÄ± kontrol et
        target_distribution = y.value_counts()
        logger.log_info(f"Hedef daÄŸÄ±lÄ±mÄ±: {target_distribution.to_dict()}")
        
        # Ã‡ok dengesiz veri uyarÄ±sÄ±
        min_class_ratio = target_distribution.min() / target_distribution.sum()
        if min_class_ratio < 0.1:
            logger.log_warning(f"Dengesiz veri seti: En az sÄ±nÄ±f oranÄ± {min_class_ratio:.2%}")
            
        # EÄŸitim-test ayrÄ±mÄ±
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, 
            test_size=test_size, 
            random_state=42, 
            stratify=y  # SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± korur
        )
        
        logger.log_info(f"Veri bÃ¶lÃ¼mÃ¼: EÄŸitim={len(X_train)}, Test={len(X_test)}")
        logger.log_info(f"EÄŸitim hedef daÄŸÄ±lÄ±mÄ±: {y_train.value_counts().to_dict()}")
        
        return X_train, X_test, y_train, y_test, available_features
        
    except Exception as e:
        logger.log_error(f"Veri hazÄ±rlama hatasÄ±: {e}", exc_info=True)
        return None


def train_model(X_train, y_train, model_type=None, params=None, use_grid_search=False):
    """
    Belirtilen model tipi ve parametrelerle makine Ã¶ÄŸrenimi modelini eÄŸitir.
    GridSearchCV ile hiperparametre optimizasyonu yapabilir.
    
    Args:
        X_train (pandas.DataFrame): EÄŸitim Ã¶zellikleri
        y_train (pandas.Series): EÄŸitim hedefleri
        model_type (str): Model tipi ('RandomForestClassifier', 'LogisticRegression')
        params (dict): Model parametreleri
        use_grid_search (bool): Hiperparametre optimizasyonu yapÄ±lsÄ±n mÄ±
    
    Returns:
        sklearn model object: EÄŸitilmiÅŸ model
        None: Hata durumunda
        
    Raises:
        Exception: Model eÄŸitimi hatalarÄ±nda
    """
    try:
        # Parametreleri config'ten al
        if model_type is None:
            model_type = config.ML_MODEL_TYPE
        if params is None:
            params = config.ML_MODEL_PARAMS.copy()
            
        logger.log_info(f"{model_type} modeli eÄŸitiliyor...")
        logger.log_info(f"Model parametreleri: {params}")
        
        # Model seÃ§imi
        if model_type == 'RandomForestClassifier':
            model = RandomForestClassifier(**params)
        elif model_type == 'LogisticRegression':
            model = LogisticRegression(**params)
        else:
            logger.log_error(f"Desteklenmeyen model tipi: {model_type}")
            return None
            
        # Grid Search ile hiperparametre optimizasyonu
        if use_grid_search:
            logger.log_info("Hiperparametre optimizasyonu yapÄ±lÄ±yor...")
            
            if model_type == 'RandomForestClassifier':
                param_grid = {
                    'n_estimators': [50, 100, 200],
                    'max_depth': [5, 10, 15, None],
                    'min_samples_split': [2, 5, 10]
                }
            elif model_type == 'LogisticRegression':
                param_grid = {
                    'C': [0.1, 1.0, 10.0],
                    'penalty': ['l1', 'l2'],
                    'solver': ['liblinear', 'saga']
                }
            else:
                param_grid = {}
                
            if param_grid:
                grid_search = GridSearchCV(
                    model, param_grid, 
                    cv=5, scoring='accuracy', 
                    n_jobs=-1, verbose=1
                )
                grid_search.fit(X_train, y_train)
                model = grid_search.best_estimator_
                logger.log_info(f"En iyi parametreler: {grid_search.best_params_}")
                logger.log_info(f"En iyi CV skoru: {grid_search.best_score_:.4f}")
            else:
                model.fit(X_train, y_train)
        else:
            # Normal eÄŸitim
            model.fit(X_train, y_train)
            
        # Cross-validation ile model performansÄ±nÄ± deÄŸerlendir
        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
        logger.log_info(f"Cross-validation accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
        
        # Ã–zellik Ã¶nemlerini logla (varsa)
        if hasattr(model, 'feature_importances_'):
            feature_importance = pd.DataFrame({
                'feature': X_train.columns,
                'importance': model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            logger.log_info("En Ã¶nemli 5 Ã¶zellik:")
            for _, row in feature_importance.head().iterrows():
                logger.log_info(f"  {row['feature']}: {row['importance']:.4f}")
                
        logger.log_info("Model eÄŸitimi tamamlandÄ±")
        return model
        
    except Exception as e:
        logger.log_error(f"Model eÄŸitimi hatasÄ±: {e}", exc_info=True)
        return None


def predict_signal(model, X_test, threshold=0.5):
    """
    EÄŸitilmiÅŸ modeli kullanarak yeni verilere dayanarak alÄ±m-satÄ±m sinyalleri 
    tahmin eder. Model Ã§Ä±ktÄ±sÄ±nÄ± AL/BEKLE/SAT sinyallerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
    
    Args:
        model: EÄŸitilmiÅŸ sklearn modeli
        X_test (pandas.DataFrame): Test Ã¶zellikleri
        threshold (float): Karar eÅŸiÄŸi (0.0-1.0 arasÄ±)
    
    Returns:
        tuple: (predictions, probabilities, signals)
        None: Hata durumunda
        
    Raises:
        Exception: Tahmin hatalarÄ±nda
    """
    try:
        logger.log_info(f"{len(X_test)} Ã¶rnek iÃ§in sinyal tahmini yapÄ±lÄ±yor...")
        
        # Tahmin yap
        predictions = model.predict(X_test)
        
        # OlasÄ±lÄ±k tahmini (varsa)
        if hasattr(model, 'predict_proba'):
            probabilities = model.predict_proba(X_test)[:, 1]  # Pozitif sÄ±nÄ±f olasÄ±lÄ±ÄŸÄ±
        else:
            probabilities = predictions.astype(float)
            
        # Sinyallere dÃ¶nÃ¼ÅŸtÃ¼r
        signals = []
        for i, (pred, prob) in enumerate(zip(predictions, probabilities)):
            if prob >= threshold + 0.2:  # YÃ¼ksek gÃ¼ven ile AL
                signal = 'BUY'
            elif prob <= threshold - 0.2:  # YÃ¼ksek gÃ¼ven ile SAT
                signal = 'SELL'
            elif pred == 1 and prob >= threshold:  # Orta gÃ¼ven ile AL
                signal = 'BUY'
            elif pred == 0 and prob <= threshold:  # Orta gÃ¼ven ile SAT
                signal = 'SELL'
            else:
                signal = 'HOLD'  # Belirsizlik durumunda bekle
                
            signals.append(signal)
            
        # Sinyal daÄŸÄ±lÄ±mÄ±nÄ± logla
        signal_counts = pd.Series(signals).value_counts()
        logger.log_info(f"Sinyal daÄŸÄ±lÄ±mÄ±: {signal_counts.to_dict()}")
        
        return predictions, probabilities, signals
        
    except Exception as e:
        logger.log_error(f"Sinyal tahmini hatasÄ±: {e}", exc_info=True)
        return None


def evaluate_model(model, X_test, y_test):
    """
    Modelin performansÄ±nÄ± Ã§eÅŸitli metriklerle deÄŸerlendirir ve detaylÄ± 
    rapor oluÅŸturur.
    
    Args:
        model: EÄŸitilmiÅŸ sklearn modeli
        X_test (pandas.DataFrame): Test Ã¶zellikleri
        y_test (pandas.Series): Test hedefleri
    
    Returns:
        dict: Performans metrikleri
        None: Hata durumunda
        
    Raises:
        Exception: DeÄŸerlendirme hatalarÄ±nda
    """
    try:
        logger.log_info("Model performansÄ± deÄŸerlendiriliyor...")
        
        # Tahminler
        y_pred = model.predict(X_test)
        
        # OlasÄ±lÄ±k tahminleri (varsa)
        if hasattr(model, 'predict_proba'):
            y_prob = model.predict_proba(X_test)[:, 1]
        else:
            y_prob = y_pred.astype(float)
            
        # Temel metrikler
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='weighted')
        recall = recall_score(y_test, y_pred, average='weighted')
        f1 = f1_score(y_test, y_pred, average='weighted')
        
        # ROC AUC (binary classification iÃ§in)
        try:
            roc_auc = roc_auc_score(y_test, y_prob)
        except:
            roc_auc = 0.5
            
        # Confusion Matrix
        cm = confusion_matrix(y_test, y_pred)
        
        # SonuÃ§larÄ± logla
        logger.log_info("=== Model Performans Raporu ===")
        logger.log_info(f"Accuracy: {accuracy:.4f}")
        logger.log_info(f"Precision: {precision:.4f}")
        logger.log_info(f"Recall: {recall:.4f}")
        logger.log_info(f"F1-Score: {f1:.4f}")
        logger.log_info(f"ROC AUC: {roc_auc:.4f}")
        logger.log_info(f"Confusion Matrix:\\n{cm}")
        
        # DetaylÄ± classification report
        class_report = classification_report(y_test, y_pred, output_dict=True)
        logger.log_info("DetaylÄ± sÄ±nÄ±f raporu:")
        for class_name, metrics in class_report.items():
            if isinstance(metrics, dict):
                logger.log_info(f"  {class_name}: Precision={metrics.get('precision', 0):.3f}, Recall={metrics.get('recall', 0):.3f}, F1={metrics.get('f1-score', 0):.3f}")
                
        # Performans metriklerini dict olarak dÃ¶ndÃ¼r
        performance_metrics = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'roc_auc': roc_auc,
            'confusion_matrix': cm.tolist(),
            'classification_report': class_report,
            'test_samples': len(y_test)
        }
        
        return performance_metrics
        
    except Exception as e:
        logger.log_error(f"Model deÄŸerlendirme hatasÄ±: {e}", exc_info=True)
        return None


def save_model(model, filename, symbol=None, metadata=None):
    """
    EÄŸitilmiÅŸ modeli joblib kullanarak dosyaya kaydeder.
    Model ile birlikte metadata da kaydedilir.
    
    Args:
        model: EÄŸitilmiÅŸ sklearn modeli
        filename (str): Dosya adÄ± (uzantÄ± olmadan)
        symbol (str): Sembol adÄ± (dosya adÄ±na eklenir)
        metadata (dict): Model hakkÄ±nda ek bilgiler
    
    Returns:
        bool: BaÅŸarÄ± durumu
        
    Raises:
        Exception: Dosya kaydetme hatalarÄ±nda
    """
    try:
        # Dosya yolunu oluÅŸtur
        if symbol:
            filename = f"{symbol}_{filename}"
            
        model_path = os.path.join(config.MODEL_SAVE_PATH, f"{filename}.joblib")
        metadata_path = os.path.join(config.MODEL_SAVE_PATH, f"{filename}_metadata.json")
        
        # Dizini oluÅŸtur
        os.makedirs(os.path.dirname(model_path), exist_ok=True)
        
        # Modeli kaydet
        joblib.dump(model, model_path)
        
        # Metadata kaydet
        if metadata is None:
            metadata = {}
            
        metadata.update({
            'model_type': type(model).__name__,
            'save_date': datetime.now().isoformat(),
            'file_path': model_path
        })
        
        import json
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
            
        logger.log_info(f"Model kaydedildi: {model_path}")
        logger.log_info(f"Metadata kaydedildi: {metadata_path}")
        
        return True
        
    except Exception as e:
        logger.log_error(f"Model kaydetme hatasÄ±: {e}", exc_info=True)
        return False


def load_model(filename, symbol=None):
    """
    KaydedilmiÅŸ modeli dosyadan yÃ¼kler.
    
    Args:
        filename (str): Dosya adÄ± (uzantÄ± olmadan)
        symbol (str): Sembol adÄ± (dosya adÄ±ndan Ã§Ä±karÄ±lÄ±r)
    
    Returns:
        tuple: (model, metadata)
        None: Hata durumunda
        
    Raises:
        Exception: Dosya okuma hatalarÄ±nda
    """
    try:
        # Dosya yolunu oluÅŸtur
        if symbol:
            filename = f"{symbol}_{filename}"
            
        model_path = os.path.join(config.MODEL_SAVE_PATH, f"{filename}.joblib")
        metadata_path = os.path.join(config.MODEL_SAVE_PATH, f"{filename}_metadata.json")
        
        if not os.path.exists(model_path):
            logger.log_warning(f"Model dosyasÄ± bulunamadÄ±: {model_path}")
            return None
            
        # Modeli yÃ¼kle
        model = joblib.load(model_path)
        
        # Metadata yÃ¼kle
        metadata = {}
        if os.path.exists(metadata_path):
            import json
            with open(metadata_path, 'r') as f:
                metadata = json.load(f)
                
        logger.log_info(f"Model yÃ¼klendi: {model_path}")
        logger.log_info(f"Model tipi: {metadata.get('model_type', 'Bilinmiyor')}")
        
        return model, metadata
        
    except Exception as e:
        logger.log_error(f"Model yÃ¼kleme hatasÄ±: {e}", exc_info=True)
        return None


def model_feature_analysis(model, feature_names):
    """
    Model Ã¶zellik analizini yapar ve Ã¶nem sÄ±ralamasÄ± oluÅŸturur.
    
    Args:
        model: EÄŸitilmiÅŸ sklearn modeli
        feature_names (list): Ã–zellik isimleri
    
    Returns:
        pandas.DataFrame: Ã–zellik Ã¶nem sÄ±ralamasÄ±
    """
    try:
        if not hasattr(model, 'feature_importances_'):
            logger.log_warning("Model Ã¶zellik Ã¶nem deÄŸerleri desteklemiyor")
            return None
            
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        # Normalize et (yÃ¼zdelik)
        importance_df['importance_pct'] = (importance_df['importance'] / importance_df['importance'].sum()) * 100
        
        logger.log_info("Ã–zellik Ã¶nem analizi:")
        for _, row in importance_df.head(10).iterrows():
            logger.log_info(f"  {row['feature']}: {row['importance']:.4f} ({row['importance_pct']:.1f}%)")
            
        return importance_df
        
    except Exception as e:
        logger.log_error(f"Ã–zellik analizi hatasÄ±: {e}")
        return None


if __name__ == "__main__":
    """
    ML Model modÃ¼lÃ¼ test kodu
    """
    print("=== AI-FTB ML Model Test ===")
    
    # Test verisi oluÅŸtur
    np.random.seed(42)
    n_samples = 1000
    
    # Ã–zellikleri simÃ¼le et
    feature_data = {
        'RSI': np.random.uniform(20, 80, n_samples),
        'MACD_Hist': np.random.normal(0, 0.5, n_samples),
        'SMA_20': np.random.uniform(90, 110, n_samples),
        'Volume_Change': np.random.normal(0, 0.3, n_samples),
        'BB_Upper': np.random.uniform(105, 115, n_samples),
        'Volatility': np.random.uniform(0.1, 0.5, n_samples)
    }
    
    # Hedef deÄŸiÅŸken (Ã¶rnek mantÄ±k: RSI > 70 ise 0, RSI < 30 ise 1, diÄŸerleri rastgele)
    target = []
    for i in range(n_samples):
        if feature_data['RSI'][i] > 70:
            target.append(0)  # AÅŸÄ±rÄ± alÄ±m, dÃ¼ÅŸÃ¼ÅŸ beklentisi
        elif feature_data['RSI'][i] < 30:
            target.append(1)  # AÅŸÄ±rÄ± satÄ±m, yÃ¼kseliÅŸ beklentisi
        else:
            target.append(np.random.choice([0, 1], p=[0.5, 0.5]))
            
    # DataFrame oluÅŸtur
    test_df = pd.DataFrame(feature_data)
    test_df['Target'] = target
    
    print(f"Test verisi oluÅŸturuldu: {len(test_df)} satÄ±r, {len(test_df.columns)-1} Ã¶zellik")
    print(f"Hedef daÄŸÄ±lÄ±mÄ±: {pd.Series(target).value_counts().to_dict()}")
    
    # Veri hazÄ±rlama testi
    print("\\n1. Veri ML iÃ§in hazÄ±rlanÄ±yor...")
    ml_data = prepare_data_for_ml(test_df)
    
    if ml_data:
        X_train, X_test, y_train, y_test, feature_names = ml_data
        print(f"âœ… Veri hazÄ±rlandÄ±: EÄŸitim={len(X_train)}, Test={len(X_test)}")
        
        # Model eÄŸitimi testi
        print("\\n2. Model eÄŸitiliyor...")
        model = train_model(X_train, y_train)
        
        if model:
            print("âœ… Model eÄŸitimi tamamlandÄ±")
            
            # Model deÄŸerlendirme testi
            print("\\n3. Model deÄŸerlendiriliyor...")
            performance = evaluate_model(model, X_test, y_test)
            
            if performance:
                print(f"âœ… Model performansÄ±: Accuracy={performance['accuracy']:.3f}")
                
                # Sinyal tahmini testi
                print("\\n4. Sinyal tahminleri...")
                prediction_result = predict_signal(model, X_test)
                
                if prediction_result:
                    predictions, probabilities, signals = prediction_result
                    signal_counts = pd.Series(signals).value_counts()
                    print(f"âœ… Sinyal tahminleri: {signal_counts.to_dict()}")
                    
                    # Model kaydetme testi
                    print("\\n5. Model kaydediliyor...")
                    metadata = {
                        'performance': performance,
                        'feature_names': feature_names,
                        'test_date': datetime.now().isoformat()
                    }
                    
                    if save_model(model, 'test_model', 'TEST', metadata):
                        print("âœ… Model kaydedildi")
                        
                        # Model yÃ¼kleme testi
                        print("\\n6. Model yÃ¼kleniyor...")
                        loaded_result = load_model('test_model', 'TEST')
                        
                        if loaded_result:
                            loaded_model, loaded_metadata = loaded_result
                            print("âœ… Model yÃ¼klendi")
                            print(f"ğŸ“Š YÃ¼klenen model tipi: {loaded_metadata.get('model_type')}")
                        else:
                            print("âŒ Model yÃ¼klenemedi")
                    else:
                        print("âŒ Model kaydedilemedi")
                else:
                    print("âŒ Sinyal tahminleri baÅŸarÄ±sÄ±z")
            else:
                print("âŒ Model deÄŸerlendirme baÅŸarÄ±sÄ±z")
        else:
            print("âŒ Model eÄŸitimi baÅŸarÄ±sÄ±z")
    else:
        print("âŒ Veri hazÄ±rlama baÅŸarÄ±sÄ±z")
        
    print("\\nML Model test tamamlandÄ±!")
