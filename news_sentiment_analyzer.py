"""
AI-FTB (AI-Powered Financial Trading Bot) News Sentiment Analyzer Module

Bu modÃ¼l, finansal haberleri Ã§eker, Ã¶n iÅŸler ve duygu analizi yaparak sayÄ±sal 
bir duygu skoru atar. TextBlob kullanarak basit, kurallara dayalÄ± duygu analizi yapar.
"""

import pandas as pd
import numpy as np
import re
import json
from datetime import datetime, timedelta
from textblob import TextBlob
import requests
import config
import logger


def fetch_financial_news(query, start_date=None, end_date=None, api_key=None):
    """
    Belirli bir sorgu (ÅŸirket adÄ±) ve tarih aralÄ±ÄŸÄ± iÃ§in finansal haberleri Ã§eker.
    NewsAPI veya benzer bir servisi kullanÄ±r. API yoksa Ã¶rnek veri dÃ¶ndÃ¼rÃ¼r.
    
    Args:
        query (str): Arama sorgusu (Ã¶rn. ÅŸirket adÄ±)
        start_date (str): BaÅŸlangÄ±Ã§ tarihi ('YYYY-MM-DD' formatÄ±nda)
        end_date (str): BitiÅŸ tarihi ('YYYY-MM-DD' formatÄ±nda)
        api_key (str): News API anahtarÄ±
    
    Returns:
        list: Haber listesi [{'title': str, 'content': str, 'date': str, 'url': str}]
        None: Hata durumunda
        
    Raises:
        Exception: API Ã§aÄŸrÄ±sÄ± veya JSON parse hatalarÄ±nda
    """
    try:
        # API anahtarÄ±nÄ± config'ten al
        if api_key is None:
            api_key = config.API_KEYS.get('NEWS_API_KEY', '')
            
        if not api_key or api_key == 'YOUR_NEWS_API_KEY_HERE':
            logger.log_warning("News API anahtarÄ± bulunamadÄ±, Ã¶rnek veriler kullanÄ±lÄ±yor")
            return _get_sample_news_data(query)
            
        # Tarih kontrolÃ¼
        if start_date is None:
            start_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
        if end_date is None:
            end_date = datetime.now().strftime('%Y-%m-%d')
            
        logger.log_info(f"Haberler Ã§ekiliyor: {query} ({start_date} - {end_date})")
        
        # NewsAPI URL'i oluÅŸtur
        base_url = "https://newsapi.org/v2/everything"
        params = {
            'q': query,
            'from': start_date,
            'to': end_date,
            'sortBy': 'relevancy',
            'language': 'en',
            'apiKey': api_key,
            'pageSize': 50  # Maksimum 50 haber
        }
        
        # API Ã§aÄŸrÄ±sÄ± yap
        response = requests.get(base_url, params=params, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        
        if data.get('status') != 'ok':
            logger.log_error(f"News API hatasÄ±: {data.get('message', 'Bilinmeyen hata')}")
            return _get_sample_news_data(query)
            
        # Haberleri iÅŸle
        articles = data.get('articles', [])
        news_list = []
        
        for article in articles:
            # Gerekli alanlarÄ± kontrol et
            if not article.get('title') or not article.get('description'):
                continue
                
            news_item = {
                'title': article.get('title', ''),
                'content': article.get('description', '') + ' ' + (article.get('content', '') or ''),
                'date': article.get('publishedAt', ''),
                'url': article.get('url', ''),
                'source': article.get('source', {}).get('name', '')
            }
            
            # Ä°Ã§erik temizle
            news_item['content'] = _clean_news_content(news_item['content'])
            
            if len(news_item['content']) > 50:  # Ã‡ok kÄ±sa iÃ§erikleri filtrele
                news_list.append(news_item)
                
        logger.log_info(f"{len(news_list)} haber Ã§ekildi ({query})")
        return news_list
        
    except requests.exceptions.RequestException as e:
        logger.log_error(f"News API baÄŸlantÄ± hatasÄ±: {e}")
        return _get_sample_news_data(query)
    except Exception as e:
        logger.log_error(f"Haber Ã§ekerken hata: {e}", exc_info=True)
        return _get_sample_news_data(query)


def _get_sample_news_data(query):
    """
    API olmadÄ±ÄŸÄ±nda kullanÄ±lacak Ã¶rnek haber verisi.
    
    Args:
        query (str): Arama sorgusu
    
    Returns:
        list: Ã–rnek haber listesi
    """
    sample_news = [
        {
            'title': f'{query} Reports Strong Q4 Earnings',
            'content': f'{query} announced better-than-expected quarterly earnings, driven by strong revenue growth and improved operational efficiency. The company exceeded analyst expectations.',
            'date': datetime.now().strftime('%Y-%m-%d'),
            'url': 'https://example.com/news1',
            'source': 'Financial Times'
        },
        {
            'title': f'{query} Faces Market Challenges',
            'content': f'{query} is navigating through challenging market conditions with increased competition and regulatory pressures affecting its business operations.',
            'date': (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d'),
            'url': 'https://example.com/news2',
            'source': 'Reuters'
        },
        {
            'title': f'{query} Announces New Product Launch',
            'content': f'{query} unveiled its latest innovation in technology, promising to revolutionize the industry with cutting-edge features and improved user experience.',
            'date': (datetime.now() - timedelta(days=2)).strftime('%Y-%m-%d'),
            'url': 'https://example.com/news3',
            'source': 'TechCrunch'
        }
    ]
    
    logger.log_info(f"Ã–rnek haber verisi kullanÄ±lÄ±yor: {len(sample_news)} haber")
    return sample_news


def _clean_news_content(content):
    """
    Haber iÃ§eriÄŸinden gereksiz karakterleri ve HTML etiketlerini temizler.
    
    Args:
        content (str): Ham haber iÃ§eriÄŸi
    
    Returns:
        str: TemizlenmiÅŸ haber iÃ§eriÄŸi
    """
    if not content:
        return ""
        
    # HTML etiketlerini kaldÄ±r
    content = re.sub(r'<[^>]+>', '', content)
    
    # URL'leri kaldÄ±r
    content = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', content)
    
    # Fazla boÅŸluklarÄ± temizle
    content = re.sub(r'\\s+', ' ', content)
    
    # Ã–zel karakterleri temizle
    content = re.sub(r'[^\\w\\s.,!?;:-]', '', content)
    
    return content.strip()


def preprocess_news_text(text):
    """
    Haber metinlerini NLP iÃ§in temizler. KÃ¼Ã§Ã¼k harfe Ã§evirme, noktalama 
    iÅŸaretlerini kaldÄ±rma ve temel temizlik iÅŸlemlerini yapar.
    
    Args:
        text (str): Ham haber metni
    
    Returns:
        str: Ã–n iÅŸlemden geÃ§miÅŸ metin
        
    Raises:
        Exception: Metin iÅŸleme hatalarÄ±nda
    """
    try:
        if not text or not isinstance(text, str):
            return ""
            
        # Temel temizlik
        text = _clean_news_content(text)
        
        # KÃ¼Ã§Ã¼k harfe Ã§evir
        text = text.lower()
        
        # Noktalama iÅŸaretlerini koru (duygu analizi iÃ§in Ã¶nemli)
        # Sadece gereksiz karakterleri kaldÄ±r
        text = re.sub(r'[^a-zA-Z0-9\\s.,!?;:-]', '', text)
        
        # Ã‡oklu boÅŸluklarÄ± tek boÅŸluÄŸa Ã§evir
        text = re.sub(r'\\s+', ' ', text)
        
        # BaÅŸÄ±ndaki ve sonundaki boÅŸluklarÄ± kaldÄ±r
        text = text.strip()
        
        return text
        
    except Exception as e:
        logger.log_error(f"Metin Ã¶n iÅŸleme hatasÄ±: {e}")
        return ""


def analyze_sentiment(text):
    """
    Ã–nceden iÅŸlenmiÅŸ metne TextBlob kullanarak duygu analizi uygular.
    -1.0 (Ã§ok negatif) ile 1.0 (Ã§ok pozitif) arasÄ± sayÄ±sal duygu skoru dÃ¶ndÃ¼rÃ¼r.
    
    Args:
        text (str): Analiz edilecek metin
    
    Returns:
        float: Duygu skoru (-1.0 ile 1.0 arasÄ±)
        
    Raises:
        Exception: Duygu analizi hatalarÄ±nda
    """
    try:
        if not text or not isinstance(text, str):
            return 0.0
            
        # TextBlob ile duygu analizi yap
        blob = TextBlob(text)
        
        # Polarity deÄŸeri -1 ile 1 arasÄ±nda
        # -1: Ã‡ok negatif, 0: NÃ¶tr, 1: Ã‡ok pozitif
        polarity = blob.sentiment.polarity
        
        # Subjectivity deÄŸeri de mevcut (0: Objektif, 1: SÃ¼bjektif)
        subjectivity = blob.sentiment.subjectivity
        
        # EÄŸer metin Ã§ok objektifse (subjectivity < 0.1), duygu skorunu azalt
        if subjectivity < 0.1:
            polarity *= 0.5
            
        # DeÄŸeri sÄ±nÄ±rlar iÃ§inde tut
        polarity = max(-1.0, min(1.0, polarity))
        
        return float(polarity)
        
    except Exception as e:
        logger.log_error(f"Duygu analizi hatasÄ±: {e}")
        return 0.0


def get_news_sentiment_for_date(symbol, date, days_back=3):
    """
    Belirli bir sembol ve tarih iÃ§in ilgili haberleri Ã§ekip, duygu analizi yapÄ±p 
    ortalama duygu skorunu dÃ¶ndÃ¼rÃ¼r.
    
    Args:
        symbol (str): Ä°ÅŸlem sembolÃ¼ (Ã¶rn. 'AAPL')
        date (str veya datetime): Ä°lgili tarih
        days_back (int): KaÃ§ gÃ¼n geriye gidilerek haber aranacak
    
    Returns:
        dict: {'sentiment_score': float, 'news_count': int, 'confidence': float}
        None: Hata durumunda
        
    Raises:
        Exception: Haber Ã§ekme veya analiz hatalarÄ±nda
    """
    try:
        # Tarihi datetime objesine Ã§evir
        if isinstance(date, str):
            date = datetime.strptime(date, '%Y-%m-%d')
            
        # Arama tarih aralÄ±ÄŸÄ±nÄ± belirle
        end_date = date.strftime('%Y-%m-%d')
        start_date = (date - timedelta(days=days_back)).strftime('%Y-%m-%d')
        
        # Sembol iÃ§in arama sorgularÄ±nÄ± config'ten al
        search_queries = config.NEWS_SEARCH_KEYWORDS.get(symbol, [symbol])
        
        all_sentiments = []
        total_news_count = 0
        
        # Her arama sorgusu iÃ§in haberleri Ã§ek
        for query in search_queries:
            news_list = fetch_financial_news(query, start_date, end_date)
            
            if not news_list:
                continue
                
            # Her haber iÃ§in duygu analizi yap
            for news in news_list:
                # BaÅŸlÄ±k ve iÃ§eriÄŸi birleÅŸtir
                full_text = f"{news['title']} {news['content']}"
                
                # Metni Ã¶n iÅŸleme tabi tut
                processed_text = preprocess_news_text(full_text)
                
                if len(processed_text) > 20:  # Ã‡ok kÄ±sa metinleri filtrele
                    sentiment = analyze_sentiment(processed_text)
                    all_sentiments.append(sentiment)
                    total_news_count += 1
                    
        # SonuÃ§larÄ± hesapla
        if not all_sentiments:
            logger.log_warning(f"Duygu analizi iÃ§in haber bulunamadÄ± ({symbol}, {date})")
            return {
                'sentiment_score': 0.0,
                'news_count': 0,
                'confidence': 0.0
            }
            
        # Ortalama duygu skorunu hesapla
        avg_sentiment = np.mean(all_sentiments)
        
        # GÃ¼ven skorunu hesapla (haber sayÄ±sÄ±na ve duygu daÄŸÄ±lÄ±mÄ±na baÄŸlÄ±)
        sentiment_std = np.std(all_sentiments) if len(all_sentiments) > 1 else 0
        confidence = min(1.0, total_news_count / 10) * (1 - sentiment_std / 2)
        
        result = {
            'sentiment_score': float(avg_sentiment),
            'news_count': total_news_count,
            'confidence': float(confidence)
        }
        
        logger.log_info(f"Duygu analizi ({symbol}, {date}): Score={avg_sentiment:.3f}, Count={total_news_count}, Confidence={confidence:.3f}")
        
        return result
        
    except Exception as e:
        logger.log_error(f"Tarihsel duygu analizi hatasÄ± ({symbol}, {date}): {e}", exc_info=True)
        return None


def batch_sentiment_analysis(symbols, start_date, end_date):
    """
    Birden fazla sembol iÃ§in belirli tarih aralÄ±ÄŸÄ±nda toplu duygu analizi yapar.
    
    Args:
        symbols (list): Sembol listesi
        start_date (str): BaÅŸlangÄ±Ã§ tarihi
        end_date (str): BitiÅŸ tarihi
    
    Returns:
        pandas.DataFrame: Tarih-sembol-duygu skoru tablosu
    """
    try:
        logger.log_info(f"Toplu duygu analizi baÅŸlÄ±yor: {len(symbols)} sembol, {start_date} - {end_date}")
        
        results = []
        date_range = pd.date_range(start=start_date, end=end_date, freq='D')
        
        for date in date_range:
            for symbol in symbols:
                sentiment_data = get_news_sentiment_for_date(symbol, date)
                
                if sentiment_data:
                    results.append({
                        'Date': date,
                        'Symbol': symbol,
                        'Sentiment_Score': sentiment_data['sentiment_score'],
                        'News_Count': sentiment_data['news_count'],
                        'Confidence': sentiment_data['confidence']
                    })
                    
        # DataFrame oluÅŸtur
        df = pd.DataFrame(results)
        
        if not df.empty:
            df = df.set_index(['Date', 'Symbol'])
            logger.log_info(f"Toplu duygu analizi tamamlandÄ±: {len(df)} kayÄ±t")
        else:
            logger.log_warning("Toplu duygu analizinde veri bulunamadÄ±")
            
        return df
        
    except Exception as e:
        logger.log_error(f"Toplu duygu analizi hatasÄ±: {e}")
        return pd.DataFrame()


def sentiment_summary_stats(sentiment_scores):
    """
    Duygu skorlarÄ± iÃ§in Ã¶zet istatistikler hesaplar.
    
    Args:
        sentiment_scores (list): Duygu skorlarÄ± listesi
    
    Returns:
        dict: Ã–zet istatistikler
    """
    try:
        if not sentiment_scores:
            return {'count': 0}
            
        scores = np.array(sentiment_scores)
        
        # Pozitif, negatif, nÃ¶tr sayÄ±larÄ±
        positive_count = np.sum(scores > config.SENTIMENT_THRESHOLD_POSITIVE)
        negative_count = np.sum(scores < config.SENTIMENT_THRESHOLD_NEGATIVE)
        neutral_count = len(scores) - positive_count - negative_count
        
        stats = {
            'count': len(scores),
            'mean': float(np.mean(scores)),
            'median': float(np.median(scores)),
            'std': float(np.std(scores)),
            'min': float(np.min(scores)),
            'max': float(np.max(scores)),
            'positive_count': int(positive_count),
            'negative_count': int(negative_count),
            'neutral_count': int(neutral_count),
            'positive_ratio': float(positive_count / len(scores)),
            'negative_ratio': float(negative_count / len(scores))
        }
        
        return stats
        
    except Exception as e:
        logger.log_error(f"Duygu istatistik hatasÄ±: {e}")
        return {'count': 0}


if __name__ == "__main__":
    """
    News Sentiment Analyzer modÃ¼lÃ¼ test kodu
    """
    print("=== AI-FTB News Sentiment Analyzer Test ===")
    
    # Test metinleri
    test_texts = [
        "Apple reports record quarterly earnings, beating analyst expectations significantly.",
        "Tesla faces challenges with production delays and regulatory scrutiny.",
        "Microsoft announces innovative cloud services expansion worldwide.",
        "The market shows mixed signals amid economic uncertainty.",
        "Google's parent company Alphabet exceeds revenue projections this quarter."
    ]
    
    # Duygu analizi testi
    print("\\n1. Duygu analizi test ediliyor...")
    sentiments = []
    
    for i, text in enumerate(test_texts, 1):
        processed = preprocess_news_text(text)
        sentiment = analyze_sentiment(processed)
        sentiments.append(sentiment)
        
        print(f"   Text {i}: {sentiment:+.3f} - {text[:50]}...")
        
    # Ã–zet istatistikler
    print("\\n2. Duygu istatistikleri:")
    stats = sentiment_summary_stats(sentiments)
    print(f"   Ortalama: {stats.get('mean', 0):.3f}")
    print(f"   Pozitif: {stats.get('positive_count', 0)}/{stats.get('count', 0)}")
    print(f"   Negatif: {stats.get('negative_count', 0)}/{stats.get('count', 0)}")
    
    # Haber Ã§ekme testi
    print("\\n3. Ã–rnek haber Ã§ekme...")
    news = fetch_financial_news('AAPL')
    
    if news:
        print(f"   âœ… {len(news)} haber Ã§ekildi")
        print(f"   ğŸ“° Ä°lk haber: {news[0]['title'][:50]}...")
        
        # Ä°lk haber iÃ§in duygu analizi
        first_news_sentiment = analyze_sentiment(
            preprocess_news_text(news[0]['title'] + ' ' + news[0]['content'])
        )
        print(f"   ğŸ“Š Ä°lk haber duygusu: {first_news_sentiment:+.3f}")
    else:
        print("   âŒ Haber Ã§ekilemedi")
        
    # Tarihsel duygu analizi testi
    print("\\n4. Tarihsel duygu analizi...")
    today = datetime.now().strftime('%Y-%m-%d')
    historical_sentiment = get_news_sentiment_for_date('AAPL', today)
    
    if historical_sentiment:
        print(f"   âœ… Tarihsel analiz tamamlandÄ±")
        print(f"   ğŸ“Š Duygu skoru: {historical_sentiment['sentiment_score']:+.3f}")
        print(f"   ğŸ“° Haber sayÄ±sÄ±: {historical_sentiment['news_count']}")
        print(f"   ğŸ¯ GÃ¼ven skoru: {historical_sentiment['confidence']:.3f}")
    else:
        print("   âŒ Tarihsel analiz baÅŸarÄ±sÄ±z")
        
    print("\\nNews Sentiment Analyzer test tamamlandÄ±!")
